<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>一只上弦酱的Blog</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-02-21T06:13:39.000Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>上弦之月</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Vultr搭建SSR梯子科学（fan）上网（qiang）</title>
    <link href="http://yoursite.com/2019/02/21/Vultr%E6%90%AD%E5%BB%BASSR%E6%A2%AF%E5%AD%90%E7%A7%91%E5%AD%A6%EF%BC%88fan%EF%BC%89%E4%B8%8A%E7%BD%91%EF%BC%88qiang%EF%BC%89/"/>
    <id>http://yoursite.com/2019/02/21/Vultr搭建SSR梯子科学（fan）上网（qiang）/</id>
    <published>2019-02-21T05:53:46.000Z</published>
    <updated>2019-02-21T06:13:39.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="一、-创建服务器"><a href="#一、-创建服务器" class="headerlink" title="一、 创建服务器"></a>一、 创建服务器</h3><p>现在主流服务器是搬瓦工和vultr，搬瓦工其实配置起来比较简单（官网后台一键傻瓜式配置）。</p><p>但是想起来某年月日往vultr账号里充过钱还没用完QAQ，所以我选择Vultr。</p><p>官网地址 ： <a href="https://www.vultr.com/" target="_blank" rel="noopener">https://www.vultr.com/</a></p><p><strong>注册账号</strong>（有时候搞活动，可以通过特定链接注册享受优惠，可以网上搜一下）</p><p>和搬瓦工不同的是，vultr需要先<strong>充值</strong>，最少10刀，可以用支付宝付款。<br><img src="https://upload-images.jianshu.io/upload_images/1731341-879a39327b672f69.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p><p>交完钱后，开始<strong>创建服务器</strong></p><p><img src="https://upload-images.jianshu.io/upload_images/1731341-e116b46107510647.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p><p>选择右上角加号创建服务器。</p><p>首先选择服务器location，试过日本，纽约，硅谷都还挺稳的，这里选硅谷的服务器。</p><p><img src="https://upload-images.jianshu.io/upload_images/1731341-5f0ca7a2a2fff29a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p><p>服务器系统默认是centos7（建议用centos7，网上教程大多基于centos7可以避免自己踩坑），现在价格最便宜居然要5刀了？？心疼QAQ<br><img src="https://upload-images.jianshu.io/upload_images/1731341-5b084d814183c50a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p><p>后面那些选项不用管，默认就好，选择deploy now<br><img src="https://upload-images.jianshu.io/upload_images/1731341-9e30cb0c80eebefd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p><p>服务器创建完成。<br><img src="https://upload-images.jianshu.io/upload_images/1731341-31d1607a8f0add48.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p><p>点击查看详情<br><img src="https://upload-images.jianshu.io/upload_images/1731341-7d5fe6f4e9f0359c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p><p>到终端ping一下自己服务器的ID，看能不能连上<br><img src="https://upload-images.jianshu.io/upload_images/1731341-142f1d684d9a7d32.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p><h3 id="二、SSR搭建梯子"><a href="#二、SSR搭建梯子" class="headerlink" title="二、SSR搭建梯子"></a>二、SSR搭建梯子</h3><p>记下服务器的账号（一般是root）和密码。</p><p>下一步是<strong>远程连接服务器</strong>，手机可以用JuiceSSH，电脑可以putty，xshell等。<br>我用的是mac自带远程连接工具，不需要下载软件。</p><p>这里举例如何用mac自带的连接工具，远程登录刚创建好的服务器。</p><ol><li><p>打开终端，选择新建远程连接<br><img src="https://upload-images.jianshu.io/upload_images/1731341-a40cfd062f31e7e6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p></li><li><p>点击服务器栏下方的加号，添加服务器ip，双击添加的服务器，选择连接。<br><img src="https://upload-images.jianshu.io/upload_images/1731341-c7a3a679b1382acb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p></li></ol><p>这里遇到一个坑，输入正确的密码却发现permission denied。</p><p><img src="https://upload-images.jianshu.io/upload_images/1731341-5e718e7da408eb0e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p><p>原因在于我不是用root登录的，解决方法：<br>直接终端运行<br><strong>ssh <a href="mailto:root@149.28.215.230" target="_blank" rel="noopener">root@149.28.215.230</a></strong></p><p><img src="https://upload-images.jianshu.io/upload_images/1731341-3bb15c0b95683451.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>可以看到登录成功了。</p><p>远程登录服务器后，运行SSR代码三连（逐条进行）</p><ol><li><p>wget –no-check-certificate <a href="https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocksR.sh" target="_blank" rel="noopener">https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocksR.sh</a></p></li><li><p>chmod +x shadowsocksR.sh</p></li><li><p>./shadowsocksR.sh 2&gt;&amp;1 | tee shadowsocksR.log</p></li></ol><p>进入如下界面</p><p><img src="https://upload-images.jianshu.io/upload_images/1731341-ef7cd2f342b2c148.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p><p>依次输入你的密码（如不设定，默认是teddysun.com），服务器端口（默认从 9000-19999 之间随机生成），加密方式（默认aes-256-cfb），回车选择协议（默认为 origin）等。</p><p>可以设置个密码然后一路回车，代码开始run，几分钟后运行结束。</p><p>（下面敲黑板！QAQ）<br><strong>出现红色字体的配置信息，非常重要，建议截图保存。（后面就是用shadowsock通过这些配置信息进行fan墙）</strong></p><p><img src="https://upload-images.jianshu.io/upload_images/1731341-72e890a8b9149a52.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p><h3 id="SSR修改密码以及配置多端口（选看）"><a href="#SSR修改密码以及配置多端口（选看）" class="headerlink" title="SSR修改密码以及配置多端口（选看）"></a>SSR修改密码以及配置多端口（选看）</h3><p>终端运行<br><strong>vi /etc/shadowsocks.json</strong></p><p>修改配置如下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">   &#123;</span><br><span class="line">    &quot;server&quot;: &quot;0.0.0.0&quot;,</span><br><span class="line">    &quot;server_ipv6&quot;: &quot;::&quot;,</span><br><span class="line">    &quot;local_address&quot;: &quot;127.0.0.1&quot;,</span><br><span class="line">    &quot;local_port&quot;: 1081,</span><br><span class="line">    &quot;port_password&quot;:&#123;</span><br><span class="line">        &quot;端口1&quot;:&quot;密码1&quot;,</span><br><span class="line">        &quot;端口2&quot;:&quot;密码2&quot;,</span><br><span class="line">        &quot;端口3&quot;:&quot;密码3&quot;,</span><br><span class="line">        &quot;端口4&quot;:&quot;密码4&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;timeout&quot;: 120,</span><br><span class="line">    &quot;udp_timeout&quot;: 60,</span><br><span class="line">    &quot;method&quot;: &quot;chacha20&quot;,</span><br><span class="line">    &quot;protocol&quot;: &quot;auth_sha1_compatible&quot;,</span><br><span class="line">    &quot;protocol_param&quot;: &quot;&quot;,</span><br><span class="line">    &quot;obfs&quot;: &quot;http_simple_compatible&quot;,</span><br><span class="line">    &quot;obfs_param&quot;: &quot;&quot;,</span><br><span class="line">    &quot;dns_ipv6&quot;: false,</span><br><span class="line">    &quot;connect_verbose_info&quot;: 0,</span><br><span class="line">    &quot;redirect&quot;: &quot;&quot;,</span><br><span class="line">    &quot;fast_open&quot;: false,</span><br><span class="line">    &quot;workers&quot;: 1</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>:wq保存退出</p><p>终端输入<br><strong>/etc/init.d/shadowsocks restart</strong></p><p>重启ssr</p><h3 id="使用Shadowsocks科学上网"><a href="#使用Shadowsocks科学上网" class="headerlink" title="使用Shadowsocks科学上网"></a>使用Shadowsocks科学上网</h3><p>github搜索shadowsocks，下载对应版本。<br>window版本 ： <a href="https://github.com/shadowsocks/shadowsocks-windows" target="_blank" rel="noopener">https://github.com/shadowsocks/shadowsocks-windows</a><br>安卓版本 ： <a href="https://github.com/shadowsocks/shadowsocks-android" target="_blank" rel="noopener">https://github.com/shadowsocks/shadowsocks-android</a><br>mac版本 ： <a href="https://github.com/shadowsocks/ShadowsocksX-NG" target="_blank" rel="noopener">https://github.com/shadowsocks/ShadowsocksX-NG</a><br>IOS版被不幸”Removed according to regulations”了。</p><p>mac版下载安装完如下<br><img src="https://upload-images.jianshu.io/upload_images/1731341-5360926802422fc3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p><p>选择服务器设置<br><img src="https://upload-images.jianshu.io/upload_images/1731341-94d20a42ebf00797.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p><p><img src="https://upload-images.jianshu.io/upload_images/1731341-e33f68988bdf7ce4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p><p>填入刚才保存的配置信息就能愉快地科学（fan）上网（qiang）了！QWQ</p><p><img src="https://upload-images.jianshu.io/upload_images/1731341-79f102b0677dea32.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p><p>但是…发现看油管很是卡顿，于是打算弄个锐速加速。</p><h3 id="centos7安装锐速加快连接速度"><a href="#centos7安装锐速加快连接速度" class="headerlink" title="centos7安装锐速加快连接速度"></a>centos7安装锐速加快连接速度</h3><p>连接服务器，运行uname -r<br><img src="https://upload-images.jianshu.io/upload_images/1731341-d616b8ec4bf68750.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p><p>以3开头说明服务器为 CentOS7 x64 系统</p><p>运行如下命令<br><strong>wget –no-check-certificate -O rskernel.sh <a href="https://raw.githubusercontent.com/uxh/shadowsocks_bash/master/rskernel.sh" target="_blank" rel="noopener">https://raw.githubusercontent.com/uxh/shadowsocks_bash/master/rskernel.sh</a> &amp;&amp; bash rskernel.sh</strong></p><p>系统开始自动下载脚本并更换内核，内核更换完毕后，系统会重启。</p><p>重新连接服务器，运行如下命令<br><strong>yum install net-tools -y &amp;&amp; wget –no-check-certificate -O appex.sh <a href="https://raw.githubusercontent.com/0oVicero0/serverSpeeder_Install/master/appex.sh" target="_blank" rel="noopener">https://raw.githubusercontent.com/0oVicero0/serverSpeeder_Install/master/appex.sh</a> &amp;&amp; bash appex.sh install</strong></p><p>接着一路回车<br><img src="https://upload-images.jianshu.io/upload_images/1731341-ea6c06a870a5a374.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p><p>显示running表示锐速安装成功以及开机自启动。<br><img src="https://upload-images.jianshu.io/upload_images/1731341-76bc9f3d4e50b7ab.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p><p>成功！QAQ</p><p>看油管果然舒服多了</p><p><img src="https://upload-images.jianshu.io/upload_images/1731341-d5a0ee7efbb6ac40.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;一、-创建服务器&quot;&gt;&lt;a href=&quot;#一、-创建服务器&quot; class=&quot;headerlink&quot; title=&quot;一、 创建服务器&quot;&gt;&lt;/a&gt;一、 创建服务器&lt;/h3&gt;&lt;p&gt;现在主流服务器是搬瓦工和vultr，搬瓦工其实配置起来比较简单（官网后台一键傻瓜式配置）。&lt;
      
    
    </summary>
    
      <category term="碎碎念" scheme="http://yoursite.com/categories/%E7%A2%8E%E7%A2%8E%E5%BF%B5/"/>
    
    
      <category term="科学上网" scheme="http://yoursite.com/tags/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/"/>
    
  </entry>
  
  <entry>
    <title>【python爬虫】Scrapy爬取百度图片并保存到本地</title>
    <link href="http://yoursite.com/2019/01/29/%E3%80%90python%E7%88%AC%E8%99%AB%E3%80%91Scrapy%E7%88%AC%E5%8F%96%E7%99%BE%E5%BA%A6%E5%9B%BE%E7%89%87%E5%B9%B6%E4%BF%9D%E5%AD%98%E5%88%B0%E6%9C%AC%E5%9C%B0/"/>
    <id>http://yoursite.com/2019/01/29/【python爬虫】Scrapy爬取百度图片并保存到本地/</id>
    <published>2019-01-29T13:54:40.000Z</published>
    <updated>2019-01-30T07:21:27.000Z</updated>
    
    <content type="html"><![CDATA[<h4 id="安装scrapy"><a href="#安装scrapy" class="headerlink" title="安装scrapy"></a>安装scrapy</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install Scrapy</span><br></pre></td></tr></table></figure><h4 id="进入终端，切换到自己项目代码的工作空间下，执行"><a href="#进入终端，切换到自己项目代码的工作空间下，执行" class="headerlink" title="进入终端，切换到自己项目代码的工作空间下，执行"></a>进入终端，切换到自己项目代码的工作空间下，执行</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy startproject baidu_pic_spider</span><br></pre></td></tr></table></figure><p><img src="https://upload-images.jianshu.io/upload_images/1731341-506b0b8a62b2f62b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p><h4 id="生成如下工程文件："><a href="#生成如下工程文件：" class="headerlink" title="生成如下工程文件："></a>生成如下工程文件：</h4><p>images是自己创建的用于存放爬到的图片目录。</p><p><img src="https://upload-images.jianshu.io/upload_images/1731341-9b6763e7255ed1db.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>在spiders目录下创建baidu_pic_spider爬虫文件，search_word可改成自己需要的搜索词。</p><h4 id="baidu-pic-spider-py"><a href="#baidu-pic-spider-py" class="headerlink" title="baidu_pic_spider.py"></a>baidu_pic_spider.py</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line">import scrapy, json</span><br><span class="line">from scrapy.http import Request</span><br><span class="line">from PicSpider.items import PicItem  # 导入item</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class PicSpider(scrapy.Spider):</span><br><span class="line">    name = &quot;pic_spider&quot;</span><br><span class="line">    allowed_domains = [&quot;http://image.baidu.com/&quot;]</span><br><span class="line">    start_urls = [&quot;http://image.baidu.com&quot;]</span><br><span class="line"></span><br><span class="line">    def parse(self, response):  # 定义解析函数</span><br><span class="line">        search_word = &apos;哈士奇&apos;  # 查找词，可修改</span><br><span class="line">        baidu_pic_url = &quot;https://image.baidu.com/search/acjson?tn=resultjson_com&amp;ipn=rj&amp;ct=201326592&amp;is=&amp;fp=result&amp;cl=2&amp;lm=-1&amp;ie=utf-8&amp;oe=utf-8&amp;adpicid=&amp;st=-1&amp;z=&amp;ic=0&amp;word=&#123;0&#125;&amp;s=&amp;se=&amp;tab=&amp;width=&amp;height=&amp;face=0&amp;istype=2&amp;qc=&amp;nc=1&amp;fr=&amp;pn=60&amp;rn=30&amp;gsm=3c&amp;1507915209449=&quot;.format(</span><br><span class="line">            search_word)  # 百度图片url</span><br><span class="line"></span><br><span class="line">        # 将带关键词参数的url交给request函数解析，返回的response通过get_pic回调函数进一步分析</span><br><span class="line">        yield Request(baidu_pic_url, meta=&#123;&quot;search_word&quot;: search_word&#125;, callback=self.get_pic, dont_filter=True)</span><br><span class="line"></span><br><span class="line">    def get_pic(self, response):  # 从图片list中获取每个pic的信息</span><br><span class="line"></span><br><span class="line">        item = PicItem()  # 实例化item</span><br><span class="line">        response_json = response.text  # 存储返回的json数据</span><br><span class="line">        response_dict = json.loads(response_json)  # 转化为字典</span><br><span class="line">        response_dict_data = response_dict[&apos;data&apos;]  # 图片的有效数据在data参数中</span><br><span class="line"></span><br><span class="line">        for pic in response_dict_data:  # pic为每个图片的信息数据，dict类型</span><br><span class="line">            if pic:</span><br><span class="line">                item[&apos;search_word&apos;] = response.meta[&apos;search_word&apos;]  # 搜索关键词赋值</span><br><span class="line">                item[&apos;pic_url&apos;] = [pic[&apos;middleURL&apos;]]  # 百度图片搜索结果url (setting中pic_url应该为数组形式)</span><br><span class="line">                item[&apos;pic_name&apos;] = pic[&apos;fromPageTitleEnc&apos;]  # 百度图片搜索结果对应的title</span><br><span class="line">                yield item</span><br></pre></td></tr></table></figure><p>新建main.py文件，方便在pycharm中运行和调试爬虫。</p><h4 id="main-py"><a href="#main-py" class="headerlink" title="main.py"></a>main.py</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># _*_ coding: utf-8 _*_</span><br><span class="line"></span><br><span class="line">from scrapy.cmdline import execute</span><br><span class="line">import sys</span><br><span class="line">import os</span><br><span class="line">sys.path.append(os.path.dirname(os.path.abspath(__file__))) #设置工程目录</span><br><span class="line">print(os.path.dirname(os.path.abspath(__file__)))</span><br><span class="line"></span><br><span class="line">execute([&quot;scrapy&quot;,&quot;crawl&quot;,&quot;pic_spider&quot;]).strip()</span><br></pre></td></tr></table></figure><p>定义item字段</p><h4 id="item-py"><a href="#item-py" class="headerlink" title="item.py"></a>item.py</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line">import scrapy</span><br><span class="line"></span><br><span class="line">class PicItem(scrapy.Item) :</span><br><span class="line">    search_word = scrapy.Field() #搜索关键字</span><br><span class="line">    pic_name = scrapy.Field() #图片标题</span><br><span class="line">    pic_url = scrapy.Field() #图片url</span><br><span class="line">    pass</span><br></pre></td></tr></table></figure><p>定义pipeline</p><h4 id="pipeline-py"><a href="#pipeline-py" class="headerlink" title="pipeline.py"></a>pipeline.py</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class PicspiderPipeline(object):</span><br><span class="line">    def process_item(self, item, spider):</span><br><span class="line">        return item</span><br></pre></td></tr></table></figure><p>在setting中对应部分修改ITEM_PIPELINES，并增加图片处理代码</p><h4 id="settings-py"><a href="#settings-py" class="headerlink" title="settings.py"></a>settings.py</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line"></span><br><span class="line">    &apos;PicSpider.pipelines.PicspiderPipeline&apos;: 300,</span><br><span class="line">    &apos;scrapy.pipelines.images.ImagesPipeline&apos; : 1,</span><br><span class="line">&#125;</span><br><span class="line">#配置pipeline，设定需要进行处理的图片路径</span><br><span class="line">IMAGES_URLS_FIELD = &quot;pic_url&quot;</span><br><span class="line"># 设置图片下载后的存储路径，放到工程目录下images文件夹</span><br><span class="line"># 获取当前目录绝对路径</span><br><span class="line">project_dir = os.path.abspath(os.path.dirname(__file__))</span><br><span class="line"># 获取images存储路径</span><br><span class="line">IMAGES_STORE = os.path.join(project_dir,&apos;images&apos;)</span><br><span class="line"></span><br><span class="line"># 设定处理图片的最小高度，宽度</span><br><span class="line">IMAGES_MIN_HEIGHT = 100</span><br><span class="line">IMAGES_MIN_WIDTH = 100</span><br></pre></td></tr></table></figure><h3 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h3><p><code>run main.py</code></p><p><img src="https://upload-images.jianshu.io/upload_images/1731341-0c1a4367ba1c514c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p><p>QwQ 你瞅啥？瞅你咋地</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;安装scrapy&quot;&gt;&lt;a href=&quot;#安装scrapy&quot; class=&quot;headerlink&quot; title=&quot;安装scrapy&quot;&gt;&lt;/a&gt;安装scrapy&lt;/h4&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td cl
      
    
    </summary>
    
      <category term="爬虫" scheme="http://yoursite.com/categories/%E7%88%AC%E8%99%AB/"/>
    
    
      <category term="scrapy" scheme="http://yoursite.com/tags/scrapy/"/>
    
  </entry>
  
  <entry>
    <title>深度学习dropout作用与原理</title>
    <link href="http://yoursite.com/2019/01/29/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0dropout%E4%BD%9C%E7%94%A8%E4%B8%8E%E5%8E%9F%E7%90%86/"/>
    <id>http://yoursite.com/2019/01/29/深度学习dropout作用与原理/</id>
    <published>2019-01-29T13:33:15.000Z</published>
    <updated>2019-01-30T07:22:50.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Dropout-作用："><a href="#Dropout-作用：" class="headerlink" title="Dropout 作用："></a>Dropout 作用：</h3><p><strong>避免过拟合。</strong></p><h3 id="Dropout与L1和L2正则化区别："><a href="#Dropout与L1和L2正则化区别：" class="headerlink" title="Dropout与L1和L2正则化区别："></a>Dropout与L1和L2正则化区别：</h3><p>L1和L2正则化通过在<strong>损失函数上增加参数的惩罚项，通过对参数大小的约束，起到类似降维的作用</strong>（若高阶项参数接近0，相当于降阶）。</p><p>进而简化模型，提高模型泛化力，避免过拟合。</p><p><strong>L1和L2正则化修改代价函数，Dropout修改神经网络本身。</strong></p><p><img src="https://upload-images.jianshu.io/upload_images/1731341-915845aa2970e51a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p><p>如图所示，dropout直接让一些神经元<strong>随机停止工作。</strong></p><p>举个不恰当的例子，大家感受一下<br>勤劳的神经元们事无巨细地干活，花大量时间<strong>把不重要的特征都学到了（过拟合）</strong>，按这种方式去做其他事效率就很低（模型泛化能力差）</p><p>现在随机挑选几个神经元组成<strong>小团队高效地工作</strong>（精兵简政），不仅速度快，效率高，工作的内容更有重点，还消除<strong>减弱了神经元节点间的联合适应性，增强了泛化能力。</strong></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;Dropout-作用：&quot;&gt;&lt;a href=&quot;#Dropout-作用：&quot; class=&quot;headerlink&quot; title=&quot;Dropout 作用：&quot;&gt;&lt;/a&gt;Dropout 作用：&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;避免过拟合。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id
      
    
    </summary>
    
      <category term="深度学习" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="深度学习" scheme="http://yoursite.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>深度学习Batch Normalization作用与原理</title>
    <link href="http://yoursite.com/2019/01/29/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0Batch-Normalization%E4%BD%9C%E7%94%A8%E4%B8%8E%E5%8E%9F%E7%90%86/"/>
    <id>http://yoursite.com/2019/01/29/深度学习Batch-Normalization作用与原理/</id>
    <published>2019-01-29T13:32:33.000Z</published>
    <updated>2019-01-30T07:22:31.000Z</updated>
    
    <content type="html"><![CDATA[<p>机器学习领域有个重要假设：<em>IID独立同分布假设</em></p><p><strong>假设训练数据和测试数据是满足相同分布</strong></p><p>独立同分布假设是通过训练集得到的模型在测试集能有好效果的基本保障。</p><h3 id="Batch-Normalization作用"><a href="#Batch-Normalization作用" class="headerlink" title="Batch Normalization作用 :"></a>Batch Normalization作用 :</h3><p><strong>在深度神经网络训练过程，使得每一层神经网络的输入保持相同分布。</strong></p><p>神经网络随着深度加深，训练变得困难。<br>relu激活函数， 残差网络都是解决梯度消失等由于深度带来的问题。<br>BN同样也是为了<strong>解决深度带来的问题</strong>。</p><h3 id="Batch-Normalization基本思想-："><a href="#Batch-Normalization基本思想-：" class="headerlink" title="Batch Normalization基本思想 ："></a>Batch Normalization基本思想 ：</h3><p>神经网络在训练过程中，随着深度加深，输入值分布会发生偏移，向取值区间上下两端靠近，如Sigmoid函数，就会导致反向传播时低层神经网络的梯度消失，这是深层网络收敛越来越慢的重要原因。</p><p><strong>Batch Normalization通过一定的规范化手段，把每层神经网络输入值的分布强行拉回到均值为0方差为1的标准正态分布。（纠偏回正过程）</strong></p><p>使得分布回到非线性函数对输入比较敏感的区域，使得损失函数能发生较大的变化（梯度变大），避免梯度消失问题。</p><p>同时梯度变大能加快模型收敛速度，提高训练速度。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;机器学习领域有个重要假设：&lt;em&gt;IID独立同分布假设&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;假设训练数据和测试数据是满足相同分布&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;独立同分布假设是通过训练集得到的模型在测试集能有好效果的基本保障。&lt;/p&gt;
&lt;h3 id=&quot;Batch-No
      
    
    </summary>
    
      <category term="深度学习" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="深度学习" scheme="http://yoursite.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>机器学习笔记（个人向）</title>
    <link href="http://yoursite.com/2019/01/29/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%AA%E4%BA%BA%E5%90%91%EF%BC%89/"/>
    <id>http://yoursite.com/2019/01/29/机器学习笔记（个人向）/</id>
    <published>2019-01-29T13:32:32.000Z</published>
    <updated>2019-01-30T07:21:50.000Z</updated>
    
    <content type="html"><![CDATA[<p>大学由于种种原因没机会学到这门课啦，出于兴趣学了下做了点小笔记qwq</p><h3 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h3><ol><li>修补缺失数据</li><li>去噪，去除极端数据</li><li>标准化 均值 缩放到0-1之间 正态化</li></ol><h3 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h3><p>目的：数据降维，减小空间， 加速算法</p><h3 id="聚类算法-k-means"><a href="#聚类算法-k-means" class="headerlink" title="聚类算法 - k-means"></a>聚类算法 - k-means</h3><ol><li>随机选择k个点作为聚类中心。</li><li>迭代循环</li></ol><ul><li>把样本分类到离它最近的分类中心 （样本重分类）。</li><li>移动聚类中心，取簇中元素的平均值作为新的聚类中心。<br>直到簇中心不再发生变化</li></ul><h3 id="k值的选择"><a href="#k值的选择" class="headerlink" title="k值的选择"></a>k值的选择</h3><ol><li>直观经验选取。</li><li>肘部法则，取明显转折点。</li><li>根据市场需求（ 如对T恤分为三类）</li></ol><h3 id="特征提取"><a href="#特征提取" class="headerlink" title="特征提取"></a>特征提取</h3><p>高维空间的特征投影到新的低维线性空间，进行降维。</p><p>无标签 </p><ul><li>PCA 主成分分析</li></ul><ol><li>数据预处理  </li><li>构造协方差矩阵 </li><li>svd奇异值分解 </li><li>取前k维特征向量 </li><li>计算投影后的k维特征向量</li></ol><p>有标签 </p><ul><li>LDA 线性判别分析 （核心在于投影后保持类间区分性）</li></ul><p>判别函数 fisher<br>J = 中心距离/类方差之和<br>J越大则类间区分性越好。</p><h3 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h3><p>决策树是一种树结构的分类器。<br>训练集通过模型，每次根据一个属性进行分支，到叶节点得到最终分类。</p><p>ID3算法 - 每次选择分类能力最强（信息增益最大）的属性<br>信息增益：增加该属性后系统不确定性降低</p><h3 id="集成学习"><a href="#集成学习" class="headerlink" title="集成学习"></a>集成学习</h3><p>把简单分类器集成在一起，形成强大的分类器。</p><p>机器学习分为</p><ul><li>有监督 分类问题<br>单独算法 : svm 决策树 神经网络 等。<br>集成算法:  boosting bagging 等。</li><li>无监督 - 聚类问题</li></ul><h3 id="bagging"><a href="#bagging" class="headerlink" title="bagging"></a>bagging</h3><p>数据集用bootstrap方法有放回采样<br>不同数据集 - 训练出k个分类器<br>对k 结果投票 输出多数分类</p><h3 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h3><p>bagging实例，随机森林由一组简单决策树集成</p><ol><li>通过bootstrap有放回采样 ，得到不同输入集，分别训练出不同分类器</li><li>vote出所有分类器得票高的分类结果</li></ol><p>随机森林一般由500-5000棵树组成。<br>一般只有2/3数据用到，1/3 out of bag数据用不到，可以拿来做交叉验证。</p><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><ol><li>大约1/3训练集不会用到，可用于天然交叉验证。</li><li>通过一系列弱决策树集成为强大分类器</li><li>combine不同分类器结果，解决过拟合问题</li><li>决策树需要进行属性选择，随机森林随机选择属性</li></ol><h3 id="stackting"><a href="#stackting" class="headerlink" title="stackting"></a>stackting</h3><p>bagging加强版<br>不同分类器输出后不直接vote，加权重再通过一个分类器。</p><h3 id="BOOSTING"><a href="#BOOSTING" class="headerlink" title="BOOSTING"></a>BOOSTING</h3><ol><li>正常生成分类器c1</li><li>着重强调c1分类错的数据，加权，再训练c2</li><li>把c1c2判别不一致的数据加权，训练c3</li></ol><p>c2解决c1分类错的地方，c3解决c1c2争端</p><ul><li>bagging并行生成几百个差不多的分类器</li><li>boosting串行生成目的性很强的分类器</li></ul><h3 id="AdaBoost"><a href="#AdaBoost" class="headerlink" title="AdaBoost"></a>AdaBoost</h3><p>每次增加分类错误样本的权重<br>最后结果是带权重分类器输出之和</p><ul><li>adaBoosting 权重固定</li><li>region boost 动态权重 取决于输入</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;大学由于种种原因没机会学到这门课啦，出于兴趣学了下做了点小笔记qwq&lt;/p&gt;
&lt;h3 id=&quot;数据预处理&quot;&gt;&lt;a href=&quot;#数据预处理&quot; class=&quot;headerlink&quot; title=&quot;数据预处理&quot;&gt;&lt;/a&gt;数据预处理&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;修补缺失数据&lt;/li
      
    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="个人笔记" scheme="http://yoursite.com/tags/%E4%B8%AA%E4%BA%BA%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>【python爬虫】BeautifulSoup爬取指定用户原创微博及图片 （代码+注释)</title>
    <link href="http://yoursite.com/2019/01/29/%E3%80%90python%E7%88%AC%E8%99%AB%E3%80%91BeautifulSoup%E7%88%AC%E5%8F%96%E6%8C%87%E5%AE%9A%E7%94%A8%E6%88%B7%E5%8E%9F%E5%88%9B%E5%BE%AE%E5%8D%9A%E5%8F%8A%E5%9B%BE%E7%89%87-%EF%BC%88%E4%BB%A3%E7%A0%81-%E6%B3%A8%E9%87%8A/"/>
    <id>http://yoursite.com/2019/01/29/【python爬虫】BeautifulSoup爬取指定用户原创微博及图片-（代码-注释/</id>
    <published>2019-01-29T13:32:30.000Z</published>
    <updated>2019-01-30T07:20:37.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="python版本-3-7"><a href="#python版本-3-7" class="headerlink" title="python版本 : 3.7"></a>python版本 : 3.7</h3><h3 id="简介"><a href="#简介" class="headerlink" title="简介 :"></a>简介 :</h3><p>把main_spider中user_id和cookie改为自己的id和cookie。</p><p>打开微博手机版 <a href="https://m.weibo.cn/" target="_blank" rel="noopener">https://m.weibo.cn/</a>  </p><p>进入指定用户主页，如李荣浩的主页 : <a href="https://m.weibo.cn/u/1739046981?uid=1739046981&amp;luicode=10000011&amp;lfid=231093_-_selffollowed" target="_blank" rel="noopener">https://m.weibo.cn/u/1739046981?uid=1739046981&amp;luicode=10000011&amp;lfid=231093_-_selffollowed</a><br>其中1739046981就是<strong>用户id</strong>。</p><p>登录微博，进入个人主页，右键审查元素，切换到Network栏，勾选perserve log。<br>在左边name栏找到m.weibo.cn（或者其他能找到cookie）的url，从右边response header中找到COOKIE并复制粘贴到代码中。</p><p><img src="https://upload-images.jianshu.io/upload_images/1731341-c4ab83862e56f2b3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p><p>main_spider.py 代码<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br></pre></td><td class="code"><pre><span class="line"># _*_ coding: utf-8 _*_</span><br><span class="line"></span><br><span class="line">import sys</span><br><span class="line">import os</span><br><span class="line">from bs4 import BeautifulSoup  # BeautifulSoup为python 爬虫库</span><br><span class="line">import requests  # 网络请求库</span><br><span class="line">import time</span><br><span class="line">from lxml import etree  # python解析库,支持HTML，XML，XPath解析</span><br><span class="line">from urllib.request import urlretrieve  # 用于图片下载</span><br><span class="line"></span><br><span class="line"># 改成自己的user_id和cookie</span><br><span class="line">user_id = YOUR_ID</span><br><span class="line">cookie = &#123;&quot;Cookie&quot;: &quot;YOUR_COOKIE&quot;&#125;</span><br><span class="line"># 初始url</span><br><span class="line">url = &apos;http://weibo.cn/%d/profile?page=1&apos;%user_id</span><br><span class="line"># 获取初始url页面html内容，获取user_id和cookie（在返回的response header中）</span><br><span class="line">html = requests.get(url, cookies = cookie).content</span><br><span class="line">print (&apos;user_id和cookie读入成功&apos;)</span><br><span class="line"></span><br><span class="line"># html元素selector</span><br><span class="line">selector = etree.HTML(html)</span><br><span class="line"># 通过xpath获取该用户微博页面总数</span><br><span class="line">pageNum = int(selector.xpath(&apos;//input[@name=&quot;mp&quot;]&apos;)[0].attrib[&apos;value&apos;])</span><br><span class="line"></span><br><span class="line">result = &quot;&quot;</span><br><span class="line">word_count = 1  # 爬取的微博和图片数</span><br><span class="line">image_count = 1</span><br><span class="line">imgsrc_list = [] # 图片链接列表</span><br><span class="line"></span><br><span class="line">print (&apos;该用户微博页数 : &apos;,pageNum)</span><br><span class="line"></span><br><span class="line">times = 5</span><br><span class="line">one_step = int(pageNum/times)</span><br><span class="line">for step in range(times):</span><br><span class="line">    if step &lt; times - 1:</span><br><span class="line">        i = int(step * one_step + 1)</span><br><span class="line">        j = int((step + 1) * one_step + 1)</span><br><span class="line">    else:</span><br><span class="line">        i = int(step * one_step + 1)</span><br><span class="line">        j = int(pageNum + 1)</span><br><span class="line">    for page in range(i, j):</span><br><span class="line">        try:</span><br><span class="line">            # 目标页面 url</span><br><span class="line">            url = &apos;http://weibo.cn/%d/profile?page=%d&apos;%(user_id,page)</span><br><span class="line">            print(&apos;正在爬取url : &apos;,url)</span><br><span class="line">            # 获取当前url页面微博内容</span><br><span class="line">            lxml = requests.get(url, cookies = cookie).content</span><br><span class="line">            selector = etree.HTML(lxml)</span><br><span class="line">            # 获取该页面微博list</span><br><span class="line">            content = selector.xpath(&apos;//span[@class=&quot;ctt&quot;]&apos;)</span><br><span class="line">            # 遍历每条微博</span><br><span class="line">            for each in content:</span><br><span class="line">                # 获取文本内容，加入result，记录条数</span><br><span class="line">                text = each.xpath(&apos;string(.)&apos;)</span><br><span class="line">                text = &quot;%d: &quot;%(word_count) +text+&quot;\n&quot;</span><br><span class="line">                result = result + text</span><br><span class="line">                word_count += 1</span><br><span class="line">            print (&apos;第%d页微博内容爬取完完成&apos;%(page))</span><br><span class="line"></span><br><span class="line">            # 把当前页面lxml实例化为soup对象</span><br><span class="line">            soup = BeautifulSoup(lxml, &quot;lxml&quot;)</span><br><span class="line">            # 获取所有图片链接</span><br><span class="line">            urllist = soup.find_all(class_=&apos;ib&apos;)</span><br><span class="line">            # 遍历每个图片url,加入</span><br><span class="line">            for imgurl in urllist:</span><br><span class="line">                imgsrc = imgurl.get(&apos;src&apos;)</span><br><span class="line">                imgsrc_list.append(imgsrc)</span><br><span class="line">                image_count += 1</span><br><span class="line">            print (&apos;第%d页图片爬取完成，获得如下图片：\n%s&apos;%(page,imgsrc_list))</span><br><span class="line">        except:</span><br><span class="line">            print (&apos;第&apos;,page,&apos;页发生错误&apos;)</span><br><span class="line"></span><br><span class="line">        time.sleep(0.001)  # 爬取每页间隔时间</span><br><span class="line">    print (&apos;正在进行第&apos;, step + 1, &apos;次停顿，防止访问次数过多&apos;)</span><br><span class="line">    time.sleep(1)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">try:</span><br><span class="line">    # 打开文本存放文件，如果不存在则新建</span><br><span class="line">    fo_txt = open(os.getcwd()+&quot;/%d&quot;%user_id+&quot;.txt&quot;, &quot;w&quot;)</span><br><span class="line">    result_path = os.getcwd() + &apos;/%d&apos; % user_id+&quot;.txt&quot;</span><br><span class="line">    print(&apos;微博内容文本存放路径为 :&apos;,result_path)</span><br><span class="line">    fo_txt.write(result)  # 将结果写入文件</span><br><span class="line">    print(&apos;爬取成功！\n该用户微博内容：\n\n%s\n文本存放路径为%s&apos; % (result,result_path))</span><br><span class="line"></span><br><span class="line">except:</span><br><span class="line">    print (&apos;微博文本内容保存失败&apos;)</span><br><span class="line"></span><br><span class="line">if not imgsrc_list:</span><br><span class="line">    print (&apos;该用户原创微博中不存在图片&apos;)</span><br><span class="line">else:</span><br><span class="line">    # 图片存放文件夹路径</span><br><span class="line">    picdir=os.getcwd()+&apos;/weibo_image&apos;+str(user_id)</span><br><span class="line">    print(picdir)</span><br><span class="line">    if os.path.exists(picdir) is False:</span><br><span class="line">        os.mkdir(picdir)  # 若不存在则新建</span><br><span class="line">    img_index = 1</span><br><span class="line"></span><br><span class="line">    # 遍历图片</span><br><span class="line">    for imgurl in imgsrc_list:</span><br><span class="line">        # 图片本地存放路径</span><br><span class="line">        img_path = picdir + &apos;/%s.jpg&apos; % img_index</span><br><span class="line">        print(&apos;正在保存&apos;,img_path)</span><br><span class="line">        # 将图片下载到本地</span><br><span class="line">        urlretrieve(imgurl, img_path)</span><br><span class="line">        img_index += 1</span><br><span class="line">    print(&apos;该用户微博图片下载完成！共有%d张图片，存放文件夹为 %s&apos;%(img_index,picdir))</span><br></pre></td></tr></table></figure></p><p>运行截图 :<br><img src="https://upload-images.jianshu.io/upload_images/1731341-9bffecfa51325bd4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p><p><img src="https://upload-images.jianshu.io/upload_images/1731341-04c7a5acdb891e9e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p><p><img src="https://upload-images.jianshu.io/upload_images/1731341-1fb2fbbf24d63622.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p><p>爬取的微博内容文件会被放到工程目录下用户对应的txt文件（自动生成）。</p><p>图片放到对应weibo_image文件下。</p><p><img src="https://upload-images.jianshu.io/upload_images/1731341-92c4801826a1dabd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p><p><img src="https://upload-images.jianshu.io/upload_images/1731341-cb62a988c7e862e0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;python版本-3-7&quot;&gt;&lt;a href=&quot;#python版本-3-7&quot; class=&quot;headerlink&quot; title=&quot;python版本 : 3.7&quot;&gt;&lt;/a&gt;python版本 : 3.7&lt;/h3&gt;&lt;h3 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; cla
      
    
    </summary>
    
      <category term="爬虫" scheme="http://yoursite.com/categories/%E7%88%AC%E8%99%AB/"/>
    
    
      <category term="BeautifulSoup" scheme="http://yoursite.com/tags/BeautifulSoup/"/>
    
      <category term="python" scheme="http://yoursite.com/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>【博客搭建】Hexo+GitHub代理（mac系统）</title>
    <link href="http://yoursite.com/2019/01/29/%E3%80%90%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E3%80%91Hexo-GitHub%E4%BB%A3%E7%90%86%EF%BC%88mac%E7%B3%BB%E7%BB%9F%EF%BC%89/"/>
    <id>http://yoursite.com/2019/01/29/【博客搭建】Hexo-GitHub代理（mac系统）/</id>
    <published>2019-01-29T13:32:29.000Z</published>
    <updated>2019-01-30T07:19:53.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><blockquote><p>积土成山，风雨兴焉；积水成渊，蛟龙生焉</p></blockquote><p>目前github博客主流是Jekyll和Hexo两种搭建方式。<br>Hexo更加简洁美观，能通过命令实现本地预览，并直接发布到web容器实现同步。</p><h4 id="1-博客本地环境搭建"><a href="#1-博客本地环境搭建" class="headerlink" title="1. 博客本地环境搭建"></a>1. 博客本地环境搭建</h4><h5 id="安装node-js和git"><a href="#安装node-js和git" class="headerlink" title="安装node.js和git"></a>安装node.js和git</h5><p>我之前就安装过node了，现在更新版本</p><h5 id="查看本机node-js版本"><a href="#查看本机node-js版本" class="headerlink" title="查看本机node.js版本"></a>查看本机node.js版本</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">node -v</span><br></pre></td></tr></table></figure><h5 id="清除node-js的cache"><a href="#清除node-js的cache" class="headerlink" title="清除node.js的cache"></a>清除node.js的cache</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo npm cache clean -f</span><br></pre></td></tr></table></figure><h5 id="安装管理node-js版本的n"><a href="#安装管理node-js版本的n" class="headerlink" title="安装管理node.js版本的n"></a>安装管理node.js版本的n</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo npm install -g n</span><br></pre></td></tr></table></figure><h5 id="安装最新版本的node-js"><a href="#安装最新版本的node-js" class="headerlink" title="安装最新版本的node.js"></a>安装最新版本的node.js</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo n stable</span><br></pre></td></tr></table></figure><h5 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">node -v  v11.0.0</span><br><span class="line">npm -v 6.4.1</span><br></pre></td></tr></table></figure><h5 id="检查git版本"><a href="#检查git版本" class="headerlink" title="检查git版本"></a>检查git版本</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Git --version </span><br><span class="line">git version 2.14.1</span><br></pre></td></tr></table></figure><h5 id="安装Hexo"><a href="#安装Hexo" class="headerlink" title="安装Hexo"></a>安装Hexo</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo npm install -g hexo</span><br><span class="line">-g表示全局安装</span><br></pre></td></tr></table></figure><h5 id="博客初始化"><a href="#博客初始化" class="headerlink" title="博客初始化"></a>博客初始化</h5><p>创建存储博客的文件my_blog，并进入。<br>cd /Users/summerchaser/Desktop/my_blog </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hexo init</span><br><span class="line">安装npm</span><br><span class="line">sudo npm install</span><br></pre></td></tr></table></figure><p>生成本地文件，开启服务器，通过<a href="http://localhost:4000查看本地博客" target="_blank" rel="noopener">http://localhost:4000查看本地博客</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hexo g</span><br><span class="line">hexo s</span><br></pre></td></tr></table></figure><h3 id="2-本地博客关联github"><a href="#2-本地博客关联github" class="headerlink" title="2. 本地博客关联github"></a>2. 本地博客关联github</h3><p>新建SummerChaser.github.io仓库</p><p>打开my_blog下 _config.yml，把最后deploy配置如下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">deploy:</span><br><span class="line">  type: git</span><br><span class="line">  repository: https://github.com/SummerChaser/SummerChaser.github.io.git</span><br><span class="line">  branch: master</span><br><span class="line">（注意type、repository、branch后均有空格）</span><br></pre></td></tr></table></figure><p>在myblog下生成静态文件并上传到服务器</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hexo g</span><br><span class="line">hexo d</span><br></pre></td></tr></table></figure><p>执行<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo d</span><br></pre></td></tr></table></figure></p><p>ERROR Deployer not found: git<br>解决 ：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-deployer-git --save</span><br></pre></td></tr></table></figure></p><h5 id="可通过-https-SummerChaser-github-io-访问博客"><a href="#可通过-https-SummerChaser-github-io-访问博客" class="headerlink" title="可通过 https://SummerChaser.github.io 访问博客"></a>可通过 <a href="https://SummerChaser.github.io" target="_blank" rel="noopener">https://SummerChaser.github.io</a> 访问博客</h5><p>添加ssh keys到GitHub后不需要每次更新博客再输入用户名和密码</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd ~/.ssh</span><br></pre></td></tr></table></figure><p>有文件夹就有密钥</p><p>更改本地博客<br>hexo g和hexo d更新到GitHub</p><p>更换主题，选择 <strong>hexo-theme-next</strong><br>cd到my_blog下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /Users/summerchaser/Desktop/my_blog </span><br><span class="line">git clone https://github.com/iissnan/hexo-theme-next themes/next</span><br></pre></td></tr></table></figure></p><p>更改blog目录下_config.yml<br>theme :landscape改为next</p><p>每次更新博客，部署文章<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hexo g  //生成缓存和静态文件</span><br><span class="line">hexo d  //重新部署到服务器</span><br></pre></td></tr></table></figure></p><p>网页端无变化<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo clean  //清楚缓存文件(db.json)和已生成的静态文件(public)</span><br></pre></td></tr></table></figure></p><p>配置next主题<br>官网 ： <a href="http://theme-next.iissnan.com/getting-started.html" target="_blank" rel="noopener">http://theme-next.iissnan.com/getting-started.html</a></p><h5 id="主题设定，选择Scheme"><a href="#主题设定，选择Scheme" class="headerlink" title="主题设定，选择Scheme"></a>主题设定，选择Scheme</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">● Muse - 默认 Scheme，这是 NexT 最初的版本，黑白主调，大量留白</span><br><span class="line">● Mist - Muse 的紧凑版本，整洁有序的单栏外观</span><br><span class="line">● Pisces - 双栏 Scheme，小家碧玉似的清新</span><br></pre></td></tr></table></figure><p>修改my_blog/themes/next/_config.yml </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">scheme: Muse</span><br><span class="line">#scheme: Mist</span><br><span class="line">#scheme: Pisces</span><br><span class="line">#scheme: Gemini</span><br><span class="line">选择Pisces去掉#</span><br></pre></td></tr></table></figure><h5 id="设置语言"><a href="#设置语言" class="headerlink" title="设置语言"></a>设置语言</h5><p>修改my_blog/_config.yml </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">language: zh-Hans</span><br></pre></td></tr></table></figure><h5 id="菜单配置"><a href="#菜单配置" class="headerlink" title="菜单配置"></a>菜单配置</h5><p>修改my_blog/themes/next/_config.yml</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">menu:</span><br><span class="line">  home: / || home</span><br><span class="line">  #about: /about/ || user</span><br><span class="line">  #tags: /tags/ || tags</span><br><span class="line">  #categories: /categories/ || th</span><br><span class="line">  archives: /archives/ || archive</span><br><span class="line">  #schedule: /schedule/ || calendar</span><br><span class="line">  #sitemap: /sitemap.xml || sitemap</span><br><span class="line">  #commonweal: /404/ || heartbeat</span><br><span class="line">去掉#</span><br></pre></td></tr></table></figure><h5 id="设置侧栏"><a href="#设置侧栏" class="headerlink" title="设置侧栏"></a>设置侧栏</h5><p>修改my_blog/themes/next/_config.yml</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sidebar:</span><br><span class="line">  # Sidebar Position, available value: left | right (only for Pisces | Gemini).</span><br><span class="line">  position: left</span><br></pre></td></tr></table></figure><h5 id="设置侧栏展示时机"><a href="#设置侧栏展示时机" class="headerlink" title="设置侧栏展示时机"></a>设置侧栏展示时机</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">display: always</span><br></pre></td></tr></table></figure><h5 id="设置头像"><a href="#设置头像" class="headerlink" title="设置头像"></a>设置头像</h5><p>修改my_blog/themes/next/_config.yml<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">修改字段 avatar， 值设置成头像的链接地址</span><br><span class="line">可放置在 source/images/ 目录下 </span><br><span class="line">配置为：avatar: /images/my_icon.jpg</span><br></pre></td></tr></table></figure></p><h5 id="设置作者名称"><a href="#设置作者名称" class="headerlink" title="设置作者名称"></a>设置作者名称</h5><p>编辑 站点配置文件，设置 author为昵称。</p><h5 id="站点描述"><a href="#站点描述" class="headerlink" title="站点描述"></a>站点描述</h5><p>编辑 站点配置文件，设置 description 字段为站点描述</p><h4 id="Hexo的一些基本命令"><a href="#Hexo的一些基本命令" class="headerlink" title="Hexo的一些基本命令"></a>Hexo的一些基本命令</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hexo g #完整命令为hexo generate,用于生成静态文件</span><br><span class="line">hexo s #完整命令为hexo server,用于启动服务器，主要用来本地预览</span><br><span class="line">hexo d #完整命令为hexo deploy,用于将本地文件发布到github等git仓库上</span><br><span class="line">hexo n &quot;my article&quot; #完整命令为hexo new,用于新建一篇名为“my article”的文章</span><br></pre></td></tr></table></figure><h4 id="发布第一篇文章"><a href="#发布第一篇文章" class="headerlink" title="发布第一篇文章"></a>发布第一篇文章</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo n &quot;Mac+Hexo+GitHub博客搭建&quot;</span><br></pre></td></tr></table></figure><p>显示<br>Created: ~/Desktop/my_blog/source/_posts/Mac-Hexo-GitHub博客搭建.md<br>编辑md文件，重新部署</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hexo g</span><br><span class="line">hexo d</span><br></pre></td></tr></table></figure><h5 id="博客初步搭建成功！"><a href="#博客初步搭建成功！" class="headerlink" title="博客初步搭建成功！"></a>博客初步搭建成功！</h5><p>效果如下 :<br><img src="https://upload-images.jianshu.io/upload_images/1731341-973a04a2714f3ffd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;积土成山，风雨兴焉；积水成渊，蛟龙生焉&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;目前github博客主流是Jek
      
    
    </summary>
    
      <category term="博客搭建" scheme="http://yoursite.com/categories/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"/>
    
    
      <category term="hexo" scheme="http://yoursite.com/tags/hexo/"/>
    
  </entry>
  
</feed>
